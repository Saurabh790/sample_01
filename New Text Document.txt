Replace ServiceConfig (Snowflake) with this
ServiceConfig.java

package com.optum.fads.caseentrybatch.api.config;

import java.io.IOException;
import java.security.PrivateKey;
import java.util.HashMap;
import java.util.Properties;

import javax.sql.DataSource;

import org.bouncycastle.pkcs.PKCSException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.jpa.repository.config.EnableJpaRepositories;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.jdbc.datasource.DriverManagerDataSource;
import org.springframework.orm.jpa.JpaTransactionManager;
import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;
import org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter;
import org.springframework.transaction.PlatformTransactionManager;
import org.springframework.transaction.annotation.EnableTransactionManagement;

import com.azure.security.keyvault.secrets.SecretClient;
import com.zaxxer.hikari.HikariDataSource;

import jakarta.persistence.EntityManagerFactory;
import net.snowflake.client.jdbc.SnowflakeBasicDataSource;

@Configuration
@EnableAutoConfiguration(exclude = { DataSourceAutoConfiguration.class })
@EnableTransactionManagement
@EnableJpaRepositories(
        entityManagerFactoryRef = "snfkEntityManagerFactory",
        transactionManagerRef = "txManagerSnFk",
        basePackages = { "com.optum.fads.caseentrybatch.api.snowflakeRepo" }
)
public class ServiceConfig {

    private static final Logger logger = LoggerFactory.getLogger(ServiceConfig.class);

    @Value("${spring.datasource.snfk.jdbcUrl}")
    private String url;
    @Value("${spring.datasource.snfk.userName}")
    private String username;
    @Value("${spring.datasource.snfk.password}")
    private String password;
    @Value("${spring.datasource.snfk.certKey}")
    private String certKey;
    @Value("${spring.datasource.snfk.passphrase}")
    private String passphrase;
    @Value("${spring.datasource.snfk.database}")
    private String database;
    @Value("${spring.datasource.snfk.schema}")
    private String schema;
    @Value("${spring.datasource.snfk.warehouse}")
    private String warehouse;
    @Value("${spring.datasource.snfk.account}")
    private String account;
    @Value("${spring.datasource.snfk.role}")
    private String role;
    @Value("${db.snfk-login.useCert}")
    private Boolean useCert;

    private final SecretClient secretClient;

    public ServiceConfig(SecretClient secretClient) {
        this.secretClient = secretClient;
    }

    @Bean(name = "fadsDataSource")
    public DataSource customDataSource() throws Exception, IOException {
        if (useCert) {
            String pemContent = secretClient.getSecret(certKey).getValue();
            logger.info("snowflake login using certificate");

            char[] pwd = secretClient.getSecret(passphrase).getValue() != null
                    ? secretClient.getSecret(passphrase).getValue().toCharArray()
                    : null;
            PrivateKey privateKey = PemKeyLoader.loadPrivateKeyPem(pemContent, pwd);

            SnowflakeBasicDataSource dataSource = new SnowflakeBasicDataSource();
            dataSource.setUrl(url);
            dataSource.setDatabaseName(database);
            dataSource.setSchema(schema);
            dataSource.setWarehouse(warehouse);
            if (account != null && !account.isEmpty()) dataSource.setAccount(account);
            if (role != null && !role.isEmpty()) dataSource.setRole(role);
            dataSource.setUser(username);
            dataSource.setPrivateKey(privateKey);

            HikariDataSource hikariDs = new HikariDataSource();
            hikariDs.setDataSource(dataSource);
            return hikariDs;
        } else {
            String user = secretClient.getSecret(username).getValue();
            String pass = secretClient.getSecret(password).getValue();
            logger.info("snowflake login using username and password");

            Properties props = new Properties();
            props.put("user", user);
            props.put("password", pass);
            props.put("database", database);
            props.put("schema", schema);
            props.put("warehouse", warehouse);
            if (role != null && !role.isEmpty()) props.put("role", role);
            if (account != null && !account.isEmpty()) props.put("account", account);

            return new DriverManagerDataSource(url, props);
        }
    }

    @Bean("snfkEntityManagerFactory")
    public LocalContainerEntityManagerFactoryBean snfkEntityManagerFactory() throws Exception {
        LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean();
        em.setDataSource(customDataSource());
        em.setPackagesToScan("com.optum.fads.caseentrybatch.api.snowflakeDomain");
        em.setJpaVendorAdapter(new HibernateJpaVendorAdapter());
        HashMap<String, Object> properties = new HashMap<>();
        properties.put("hibernate.allow_update_outside_transaction", true);
        properties.put("hibernate.dialect", "com.optum.fads.caseentrybatch.api.config.SnowflakeDialect");
        em.setJpaPropertyMap(properties);
        return em;
    }

    @Bean("txManagerSnFk")
    public PlatformTransactionManager txManagerSnFk(
            @Qualifier("snfkEntityManagerFactory") EntityManagerFactory snfkEntityManagerFactory) {
        JpaTransactionManager txManager = new JpaTransactionManager();
        txManager.setEntityManagerFactory(snfkEntityManagerFactory);
        return txManager;
    }

    @Bean(name = "jdbcSnowflake")
    public JdbcTemplate snowflakeJdbcTemplate(@Qualifier("fadsDataSource") DataSource ds) {
        return new JdbcTemplate(ds);
    }
}
2) Replace ServiceConfigSQL (SQL Server) with this
ServiceConfigSQL.java

package com.optum.fads.caseentrybatch.api.config;

import javax.sql.DataSource;

import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.boot.autoconfigure.batch.BatchDataSource;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.data.jpa.repository.config.EnableJpaRepositories;
import org.springframework.jdbc.datasource.DriverManagerDataSource;
import org.springframework.orm.jpa.JpaTransactionManager;
import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;
import org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter;
import org.springframework.transaction.PlatformTransactionManager;
import org.springframework.transaction.annotation.EnableTransactionManagement;

import com.azure.security.keyvault.secrets.SecretClient;

import jakarta.persistence.EntityManagerFactory;

@Configuration
@EnableAutoConfiguration(exclude = { DataSourceAutoConfiguration.class })
@EnableTransactionManagement
@EnableJpaRepositories(
        entityManagerFactoryRef = "sqlEntityManagerFactory",
        transactionManagerRef = "txManagerSQL",
        basePackages = "com.optum.fads.caseentrybatch.api.repo"
)
public class ServiceConfigSQL {

    @Value("${spring.datasource.sql.userName}")
    private String userName;
    @Value("${spring.datasource.sql.password}")
    private String password;
    @Value("${spring.datasource.sql.jdbcUrl}")
    private String url;
    @Value("${spring.datasource.sql.driverClassName}")
    private String driverClassName;

    private final SecretClient secretClient;

    public ServiceConfigSQL(SecretClient secretClient) {
        this.secretClient = secretClient;
    }

    @Primary
    @BatchDataSource
    @Bean(name = "fadsSQLDataSource")
    public DataSource fadsSQLDataSource() {
        String userNameValue = secretClient.getSecret(userName).getValue();
        String passwordValue = secretClient.getSecret(password).getValue();

        DriverManagerDataSource dataSource = new DriverManagerDataSource();
        dataSource.setDriverClassName(driverClassName);
        dataSource.setUsername(userNameValue);
        dataSource.setPassword(passwordValue);
        dataSource.setUrl(url);
        return dataSource;
    }

    @Bean(name = "sqlEntityManagerFactory")
    public LocalContainerEntityManagerFactoryBean sqlEntityManagerFactory() {
        LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean();
        em.setDataSource(fadsSQLDataSource());
        em.setPackagesToScan("com.optum.fads.caseentrybatch.api.domain");
        em.setJpaVendorAdapter(new HibernateJpaVendorAdapter());
        return em;
    }

    @Primary
    @Bean(name = "txManagerSQL")
    public PlatformTransactionManager txManagerSQL(
            @Qualifier("sqlEntityManagerFactory") EntityManagerFactory sqlEntityManagerFactory) {
        JpaTransactionManager txManager = new JpaTransactionManager();
        txManager.setEntityManagerFactory(sqlEntityManagerFactory);
        return txManager;
    }
}
3) Update batch step transaction manager
CaseBatchJobConfig.java

Use qualifier so chunk transaction uses SQL manager:

import org.springframework.beans.factory.annotation.Qualifier;
...
@Bean
public Step processBatchIdStep(
        JobRepository jobRepository,
        @Qualifier("txManagerSQL") PlatformTransactionManager transactionManager,
        BatchIdReader batchIdReader,
        BatchIdProcessor batchIdProcessor
) {
    return new StepBuilder("processBatchIdStep", jobRepository)
            .<Integer, Integer>chunk(CHUNK_SIZE, transactionManager)
            .reader(batchIdReader)
            .processor(batchIdProcessor)
            .writer(items -> { })
            .build();
}
4) Optional property
If you already created BATCH_* tables manually, add in application.properties:

spring.batch.jdbc.initialize-schema=never
After these changes, your startup error about more than one 'primary' bean found among candidates: [fadsDataSource, fadsSQLDataSource] should be resolved.
